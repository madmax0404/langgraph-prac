{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a00d9d",
   "metadata": {},
   "source": [
    "# [Source](https://langchain-ai.github.io/langgraph/tutorials/get-started/3-add-memory/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ef6dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_ollama import ChatOllama\n",
    "from typing import Annotated\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e85f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=os.getenv(\"ollama_model\"),\n",
    "    reasoning=True,\n",
    "    model_kwargs={\"think\": \"high\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e99f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc128a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b900310",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da70c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ab1495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x76b42c717320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf703d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x76b42c717320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2124b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x76b42c717320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c02c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53544a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e95ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "811ddf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fb6aded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Max.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Max! ðŸ‘‹ How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hi there! My name is Max.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d371946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, I remember youâ€™re Max! What can I help you with today?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9119ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Iâ€™m sorryâ€”I donâ€™t have a record of your name from our previous interactions. Could you let me know what youâ€™d like me to call you?\n"
     ]
    }
   ],
   "source": [
    "# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95523d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Max.', additional_kwargs={}, response_metadata={}, id='85d29b2a-82ef-4b65-b123-d2e39d1244dd'), AIMessage(content='Hello, Max! ðŸ‘‹ How can I help you today?', additional_kwargs={'reasoning_content': 'User says: \"Hi there! My name is Max.\" Simple greeting. Should respond friendly.'}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-09-27T11:24:31.23799758Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4515941585, 'load_duration': 3120225108, 'prompt_eval_count': 1342, 'prompt_eval_duration': 996123934, 'eval_count': 42, 'eval_duration': 398867173, 'model_name': 'gpt-oss:20b'}, id='run--5af9c5f3-4ed3-4104-8e2b-ecf6d9928169-0', usage_metadata={'input_tokens': 1342, 'output_tokens': 42, 'total_tokens': 1384}), HumanMessage(content='Remember my name?', additional_kwargs={}, response_metadata={}, id='5afce645-dceb-40ad-a02d-8e88c1caed49'), AIMessage(content='Yes, I remember youâ€™re Max! What can I help you with today?', additional_kwargs={'reasoning_content': 'We need to respond: Yes we remember the name, maybe mention we are ChatGPT.'}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-09-27T11:24:31.871769939Z', 'done': True, 'done_reason': 'stop', 'total_duration': 622348499, 'load_duration': 113461666, 'prompt_eval_count': 1369, 'prompt_eval_duration': 56238445, 'eval_count': 44, 'eval_duration': 404779894, 'model_name': 'gpt-oss:20b'}, id='run--8151c978-7654-44dd-b300-a026f5eb6ef7-0', usage_metadata={'input_tokens': 1369, 'output_tokens': 44, 'total_tokens': 1413})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f09b948-9da5-6747-8004-48eed300717d'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-09-27T11:24:31.873817+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f09b948-97ab-6b0f-8003-496f58842dd8'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2057c181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_prac_workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
